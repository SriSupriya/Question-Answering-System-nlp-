{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jan_feb.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CONTENT_lower\"] = df[\"CONTENT\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3bcf3899cfc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchained_assignment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "full_df = pd.read_csv(\"jan_feb.csv\", nrows=5000)\n",
    "df = full_df[[\"text\"]]\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b0bddb18eca4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchained_assignment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-7f7733446754>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-7f7733446754>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install -U pip setuptools wheel\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install -U pip setuptools wheel\n",
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(\"jan_feb.csv\", nrows=5000)\n",
    "df = full_df[[\"CONTENT\"]]\n",
    "df[\"CONTENT\"] = df[\"CONTENT\"].astype(str)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Supriya\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - spacy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.2               |   py37h03978a9_0         3.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.1 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.10.1-py37h03978a9_0 --> 4.10.2-py37h03978a9_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.10.2         | 3.1 MB    |            |   0% \n",
      "conda-4.10.2         | 3.1 MB    |            |   1% \n",
      "conda-4.10.2         | 3.1 MB    | 3          |   4% \n",
      "conda-4.10.2         | 3.1 MB    | 7          |   8% \n",
      "conda-4.10.2         | 3.1 MB    | #3         |  14% \n",
      "conda-4.10.2         | 3.1 MB    | #7         |  18% \n",
      "conda-4.10.2         | 3.1 MB    | ##1        |  21% \n",
      "conda-4.10.2         | 3.1 MB    | ##4        |  25% \n",
      "conda-4.10.2         | 3.1 MB    | ###        |  31% \n",
      "conda-4.10.2         | 3.1 MB    | ###7       |  37% \n",
      "conda-4.10.2         | 3.1 MB    | ####1      |  42% \n",
      "conda-4.10.2         | 3.1 MB    | ####6      |  47% \n",
      "conda-4.10.2         | 3.1 MB    | #####1     |  51% \n",
      "conda-4.10.2         | 3.1 MB    | #####5     |  56% \n",
      "conda-4.10.2         | 3.1 MB    | ######     |  61% \n",
      "conda-4.10.2         | 3.1 MB    | ######6    |  66% \n",
      "conda-4.10.2         | 3.1 MB    | #######1   |  71% \n",
      "conda-4.10.2         | 3.1 MB    | #######6   |  77% \n",
      "conda-4.10.2         | 3.1 MB    | ########1  |  82% \n",
      "conda-4.10.2         | 3.1 MB    | ########6  |  86% \n",
      "conda-4.10.2         | 3.1 MB    | #########  |  90% \n",
      "conda-4.10.2         | 3.1 MB    | #########5 |  95% \n",
      "conda-4.10.2         | 3.1 MB    | #########9 | 100% \n",
      "conda-4.10.2         | 3.1 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTICLE_ID</th>\n",
       "      <th>EXTERNAL_ID</th>\n",
       "      <th>EXTERNAL_AUTHOR_ID</th>\n",
       "      <th>HEADLINE</th>\n",
       "      <th>full_text_lsh</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>ARTICLE_URL</th>\n",
       "      <th>MEDIA_PROVIDER</th>\n",
       "      <th>REGION</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>...</th>\n",
       "      <th>WORKFLOW_AUTHORTAGS</th>\n",
       "      <th>FIRST_ENGAGEMENT_ACTIVITY</th>\n",
       "      <th>LAST_ENGAGEMENT_ACTIVITY</th>\n",
       "      <th>DURATION_PUBLISHED_TO_FIRST</th>\n",
       "      <th>DURATION_FIRST_TO_LAST</th>\n",
       "      <th>FIRST_ASSIGNMENT_DATE</th>\n",
       "      <th>HASHTAG_MENTIONED</th>\n",
       "      <th>DOMAIN_MENTIONED</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>INFLUENCER_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.199730e+12</td>\n",
       "      <td>1.357E+18</td>\n",
       "      <td>3.477949e+07</td>\n",
       "      <td>TWEET FROM: Ocrevus_Prime</td>\n",
       "      <td>'@soxmachine_josh It’s so subjective. I know f...</td>\n",
       "      <td>'@soxmachine_josh It’s so subjective. I know f...</td>\n",
       "      <td>http://twitter.com/34779492/statuses/135699976...</td>\n",
       "      <td>TWITTER</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter.com/ocrevus_prime</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.199730e+12</td>\n",
       "      <td>1.357E+18</td>\n",
       "      <td>9.113400e+17</td>\n",
       "      <td>TWEET FROM: VIXC_News</td>\n",
       "      <td>Biogen Stock Dives; Aducaumab Approval Expecte...</td>\n",
       "      <td>Biogen Stock Dives; Aducaumab Approval Expecte...</td>\n",
       "      <td>http://twitter.com/911339992194134016/statuses...</td>\n",
       "      <td>TWITTER</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>Media &amp; Investors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#vixc,#commentary,#eweathernews</td>\n",
       "      <td>vixc.com</td>\n",
       "      <td>twitter.com/vixc_news</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.199730e+12</td>\n",
       "      <td>1.357E+18</td>\n",
       "      <td>9.487410e+17</td>\n",
       "      <td>TWEET FROM: Brandon_Beaber</td>\n",
       "      <td>'@eatsruns People who are older have a higher ...</td>\n",
       "      <td>'@eatsruns People who are older have a higher ...</td>\n",
       "      <td>http://twitter.com/948740923000700928/statuses...</td>\n",
       "      <td>TWITTER</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>HCPs &amp; Hospitals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter.com/brandon_beaber</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.199730e+12</td>\n",
       "      <td>1.357E+18</td>\n",
       "      <td>2.809042e+09</td>\n",
       "      <td>TWEET FROM: aubagio</td>\n",
       "      <td>He is over yall shit 😭😭😭😭 https://t.co/GMRc76Th7w</td>\n",
       "      <td>He is over yall shit 😭😭😭😭 https://t.co/GMRc76Th7w</td>\n",
       "      <td>http://twitter.com/2809042468/statuses/1356996...</td>\n",
       "      <td>TWITTER</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter.com/aubagio</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.199730e+12</td>\n",
       "      <td>1.357E+18</td>\n",
       "      <td>2.809042e+09</td>\n",
       "      <td>TWEET FROM: aubagio</td>\n",
       "      <td>hugging his arm instead of holding hands &amp;gt;&amp;...</td>\n",
       "      <td>hugging his arm instead of holding hands &amp;gt;&amp;...</td>\n",
       "      <td>http://twitter.com/2809042468/statuses/1356995...</td>\n",
       "      <td>TWITTER</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter.com/aubagio</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ARTICLE_ID EXTERNAL_ID  EXTERNAL_AUTHOR_ID                    HEADLINE  \\\n",
       "0  1.199730e+12   1.357E+18        3.477949e+07   TWEET FROM: Ocrevus_Prime   \n",
       "1  1.199730e+12   1.357E+18        9.113400e+17       TWEET FROM: VIXC_News   \n",
       "2  1.199730e+12   1.357E+18        9.487410e+17  TWEET FROM: Brandon_Beaber   \n",
       "3  1.199730e+12   1.357E+18        2.809042e+09         TWEET FROM: aubagio   \n",
       "4  1.199730e+12   1.357E+18        2.809042e+09         TWEET FROM: aubagio   \n",
       "\n",
       "                                       full_text_lsh  \\\n",
       "0  '@soxmachine_josh It’s so subjective. I know f...   \n",
       "1  Biogen Stock Dives; Aducaumab Approval Expecte...   \n",
       "2  '@eatsruns People who are older have a higher ...   \n",
       "3  He is over yall shit 😭😭😭😭 https://t.co/GMRc76Th7w   \n",
       "4  hugging his arm instead of holding hands &gt;&...   \n",
       "\n",
       "                                             CONTENT  \\\n",
       "0  '@soxmachine_josh It’s so subjective. I know f...   \n",
       "1  Biogen Stock Dives; Aducaumab Approval Expecte...   \n",
       "2  '@eatsruns People who are older have a higher ...   \n",
       "3  He is over yall shit 😭😭😭😭 https://t.co/GMRc76Th7w   \n",
       "4  hugging his arm instead of holding hands &gt;&...   \n",
       "\n",
       "                                         ARTICLE_URL MEDIA_PROVIDER  \\\n",
       "0  http://twitter.com/34779492/statuses/135699976...        TWITTER   \n",
       "1  http://twitter.com/911339992194134016/statuses...        TWITTER   \n",
       "2  http://twitter.com/948740923000700928/statuses...        TWITTER   \n",
       "3  http://twitter.com/2809042468/statuses/1356996...        TWITTER   \n",
       "4  http://twitter.com/2809042468/statuses/1356995...        TWITTER   \n",
       "\n",
       "          REGION LANGUAGE  ... WORKFLOW_AUTHORTAGS FIRST_ENGAGEMENT_ACTIVITY  \\\n",
       "0  United States  English  ...                 NaN                       NaN   \n",
       "1  United States  English  ...   Media & Investors                       NaN   \n",
       "2        Unknown  English  ...    HCPs & Hospitals                       NaN   \n",
       "3        Unknown  English  ...                 NaN                       NaN   \n",
       "4        Unknown  English  ...                 NaN                       NaN   \n",
       "\n",
       "  LAST_ENGAGEMENT_ACTIVITY DURATION_PUBLISHED_TO_FIRST  \\\n",
       "0                      NaN                         NaN   \n",
       "1                      NaN                         NaN   \n",
       "2                      NaN                         NaN   \n",
       "3                      NaN                         NaN   \n",
       "4                      NaN                         NaN   \n",
       "\n",
       "   DURATION_FIRST_TO_LAST  FIRST_ASSIGNMENT_DATE  \\\n",
       "0                     NaN                    NaN   \n",
       "1                     NaN                    NaN   \n",
       "2                     NaN                    NaN   \n",
       "3                     NaN                    NaN   \n",
       "4                     NaN                    NaN   \n",
       "\n",
       "                 HASHTAG_MENTIONED  DOMAIN_MENTIONED  \\\n",
       "0                              NaN               NaN   \n",
       "1  #vixc,#commentary,#eweathernews          vixc.com   \n",
       "2                              NaN               NaN   \n",
       "3                              NaN               NaN   \n",
       "4                              NaN               NaN   \n",
       "\n",
       "                       SOURCE  INFLUENCER_SCORE  \n",
       "0   twitter.com/ocrevus_prime              50.0  \n",
       "1       twitter.com/vixc_news              62.0  \n",
       "2  twitter.com/brandon_beaber              55.0  \n",
       "3         twitter.com/aubagio              20.0  \n",
       "4         twitter.com/aubagio              20.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv(\"jan_feb.csv\", nrows=5000)\n",
    "df = full_df[[\"CONTENT\"]]\n",
    "df[\"CONTENT\"] = df[\"CONTENT\"].astype(str)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CONTENT_CP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'@soxmachine_josh It’s so subjective. I know f...</td>\n",
       "      <td>'@soxmachine_josh it’s so subjective. i know f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biogen Stock Dives; Aducaumab Approval Expecte...</td>\n",
       "      <td>biogen stock dives; aducaumab approval expecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'@eatsruns People who are older have a higher ...</td>\n",
       "      <td>'@eatsruns people who are older have a higher ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is over yall shit 😭😭😭😭 https://t.co/GMRc76Th7w</td>\n",
       "      <td>he is over yall shit 😭😭😭😭 https://t.co/gmrc76th7w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hugging his arm instead of holding hands &amp;gt;&amp;...</td>\n",
       "      <td>hugging his arm instead of holding hands &amp;gt;&amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  \\\n",
       "0  '@soxmachine_josh It’s so subjective. I know f...   \n",
       "1  Biogen Stock Dives; Aducaumab Approval Expecte...   \n",
       "2  '@eatsruns People who are older have a higher ...   \n",
       "3  He is over yall shit 😭😭😭😭 https://t.co/GMRc76Th7w   \n",
       "4  hugging his arm instead of holding hands &gt;&...   \n",
       "\n",
       "                                          CONTENT_CP  \n",
       "0  '@soxmachine_josh it’s so subjective. i know f...  \n",
       "1  biogen stock dives; aducaumab approval expecte...  \n",
       "2  '@eatsruns people who are older have a higher ...  \n",
       "3  he is over yall shit 😭😭😭😭 https://t.co/gmrc76th7w  \n",
       "4  hugging his arm instead of holding hands &gt;&...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CONTENT_CP\"] = df[\"CONTENT\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"CONTENT_CP\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>text_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'@soxmachine_josh It’s so subjective. I know f...</td>\n",
       "      <td>soxmachinejosh It’s so subjective I know for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biogen Stock Dives; Aducaumab Approval Expecte...</td>\n",
       "      <td>Biogen Stock Dives Aducaumab Approval Expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'@eatsruns People who are older have a higher ...</td>\n",
       "      <td>eatsruns People who are older have a higher ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is over yall shit 😭😭😭😭 https://t.co/GMRc76Th7w</td>\n",
       "      <td>He is over yall shit 😭😭😭😭 httpstcoGMRc76Th7w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hugging his arm instead of holding hands &amp;gt;&amp;...</td>\n",
       "      <td>hugging his arm instead of holding hands gtgtgtgt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  \\\n",
       "0  '@soxmachine_josh It’s so subjective. I know f...   \n",
       "1  Biogen Stock Dives; Aducaumab Approval Expecte...   \n",
       "2  '@eatsruns People who are older have a higher ...   \n",
       "3  He is over yall shit 😭😭😭😭 https://t.co/GMRc76Th7w   \n",
       "4  hugging his arm instead of holding hands &gt;&...   \n",
       "\n",
       "                                       text_wo_punct  \n",
       "0  soxmachinejosh It’s so subjective I know for c...  \n",
       "1  Biogen Stock Dives Aducaumab Approval Expected...  \n",
       "2  eatsruns People who are older have a higher ch...  \n",
       "3       He is over yall shit 😭😭😭😭 httpstcoGMRc76Th7w  \n",
       "4  hugging his arm instead of holding hands gtgtgtgt  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"text_wo_punct\"] = df[\"CONTENT\"].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Supriya/nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Supriya/nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-46c1bdfb30d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;34m\", \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Supriya/nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Supriya\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding-One-hot encoding (CountVectorizing)\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document hey?',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'hey', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = vectorizer2.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and this is the third', 'document is the second document', 'is this the first document', 'this document is the second', 'this is the first document', 'this is the third one', 'this the first document hey']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [1 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding-TF-IDF transforming\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = transformer.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46941728, 0.61722732, 0.        , 0.3645444 ,\n",
       "        0.        , 0.        , 0.3645444 , 0.        , 0.3645444 ],\n",
       "       [0.        , 0.65782665, 0.        , 0.        , 0.25543054,\n",
       "        0.        , 0.60953246, 0.25543054, 0.        , 0.25543054],\n",
       "       [0.53248519, 0.        , 0.        , 0.        , 0.22314313,\n",
       "        0.53248519, 0.        , 0.22314313, 0.53248519, 0.22314313],\n",
       "       [0.        , 0.35416436, 0.46568358, 0.65632693, 0.27504022,\n",
       "        0.        , 0.        , 0.27504022, 0.        , 0.27504022]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding-Word2Vec\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
